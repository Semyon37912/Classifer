## В этом задании нужно было предсказать кто из пасажиров переместится в измерении, а кто нет.

### Для начала провел EDA:
1.Разбил признак "Cabin" на 2 признака: "Deck" - номер пасубы и "Side" - расположение каюты слева или справа.
2.Преобразовал категориальные признаки в числовые.
3.Для заполнения пропусков я использовал метод "KNN".
4.Для удаления выбросов использовал цикл из методов "Local Outlier Factor".

### Подготовил данные для машинного обучения:
1.Передал переменной X нецелевые признаки, а переменной y целевой.
2.Разбил данные на тренировочные и тестовые.
3.Провел нормализацию данных.

### Обучил модели на данных:
1.Обучил модели на тренировочной выборке: 
"Decision Tree", "SVM", "Naive Bayes", "Logistic Regression"

2.Поверил качество классификации на тестовой с помощью:
?...

3.Качество предсказания было уже приемлемым, но для улучшения качества решил использовать ансамбли: 
"Staking", "Boosting", "Bagging", "XGBoost", "Random Forest"

4.Для нахождения наилучших гиперпараметров "Random Forest", использовал метод "Randomized Search".

### Вывод:
Наилучшим образом паказал себя ансамбль "Random Forest", именно на нем и было принято решение делать финальное предсказание.

## Алгоритмы работы методов использованных в этой работе:
### Заполнение пропусков с помощью KNN - 
  Когда KNN используется для заполнения пропущенных значений, сначала определяется расстояние между
наблюдениями с помощью какой-либо метрики расстояния, например, евклидова или Манхэттенская метрики. Затем находятся k ближайших соседей
с известными значениями для данной переменной. Значение пропущенной переменной затем вычисляется путем усреднения или медианы значений
переменной у найденных k ближайших соседей.

### Поиск выбросов с помощью Local Outlier Factor - 
Алгоритм LOF использует KNN для определения соседей каждой точки. Алгоритм начинает с
определения k ближайших соседей каждой точки и вычисления расстояний до этих соседей. Затем для каждой точки вычисляется локальный
коэффициент выброса (local outlier factor), который определяет степень отличия плотности точки от плотности ее соседей.
Локальный коэффициент выброса вычисляется путем сравнения плотности точки с плотностью ее соседей. Если плотность точки меньше
плотности ее соседей, то локальный коэффициент выброса больше единицы, что указывает на то, что точка скорее всего является выбросом.
Если плотность точки сравнима с плотностью ее соседей, то локальный коэффициент выброса близок к единице, что указывает на то, что точка
вероятно не является выбросом.

### Decision Tree -
Процесс построения дерева решений начинается с корневого узла, который представляет все доступные данные. Затем для каждого узла
производится разбиение данных на основе признаков, чтобы максимизировать различие между классами или минимизировать ошибку
прогнозирования. Это выполняется путем определения признака, который наиболее эффективно разделяет данные на классы. Эффективность
разбиения оценивается на основе различных метрик, таких как критерий Джини или энтропия Шеннона.
После разбиения данных на подмножества процесс повторяется для каждого подмножества, создавая новые внутренние узлы и ветви, пока не
будет достигнут критерий остановки. Критерии остановки могут включать максимальную глубину дерева, минимальное количество наблюдений в
каждом листе или минимальное значение ошибки.

